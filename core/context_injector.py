# Generated by: Ollama GLM-5

import re
from core import user_lattice as jane_lattice
from core import knowledge

TEMPLATE_USERS = {
    "jane": "__template__",
    "kart": "__template__kart__",
    "sean": "__template__sean__",
}

def build_context_header(username, agent_name="jane") -> str:
    """
    Load agent lattice memory into a system prompt header.
    Falls back to template seeds for domains with no personal memory.
    """
    template_user = TEMPLATE_USERS.get(agent_name, "__template__" + agent_name + "__")
    label = agent_name.upper() + " MEMORY"
    # 1. Crisis Check (personal only)
    crisis_nodes = jane_lattice.crisis_check(username)

    # 2. Context Summary (personal nodes per domain)
    context_nodes = jane_lattice.get_context_summary(username)

    # 3. Template seeds as fallback for empty domains
    template_nodes = jane_lattice.get_context_summary(template_user)
    for domain, node in template_nodes.items():
        if domain not in context_nodes:
            context_nodes[domain] = node

    # If still nothing, return minimal header
    if not crisis_nodes and not context_nodes:
        return chr(10).join(["---" + label + ": " + username + "---", "(No memory)", "---END MEMORY---"])

    lines = []
    lines.append(f"---{label}: {username}---")

    for node in crisis_nodes:
        lines.append(f"[CRISIS] {node['domain']}/{node['depth']}/{node['temporal']}: {node['content']}")

    for domain, node in context_nodes.items():
        prefix = "[TPL] " if node.get("username") == template_user else ""
        lines.append(f"{prefix}{node['domain']}/{node['depth']}/{node['temporal']}: {node['content']}")

    # For Kart: append live knowledge context if available
    if agent_name == "kart":
        try:
            k_context = knowledge.build_knowledge_context(username, query="system state current tasks", max_chars=800)
            if k_context and "No knowledge" not in k_context:
                lines.append("[KNOWLEDGE]")
                lines.append(k_context[:800])
        except Exception:
            pass
    lines.append("---END MEMORY---")
    return chr(10).join(lines)

def extract_and_store(username, user_message, jane_response) -> None:
    """
    Parse conversation and store facts using keyword matching.
    """
    # Combine input for analysis, though focus is usually on user disclosures
    text_to_analyze = f"{user_message} {jane_response}"
    sentences = re.split(r'[.!?]', text_to_analyze)
    
    # Rule definitions: (keyword_list, domain, depth, temporal)
    # Ordered by specificity
    rules = [
        # Crisis (Depth 23)
        (['kill myself', 'suicide', 'want to die', 'end it all', 'hurt myself'], 'crisis', 23, 'triggered'),
        
        # Identity (Depth ~18-20)
        (['i\'m bi', 'i am bi', 'i\'m gay', 'i am gay', 'i\'m trans', 'i am trans', 
          'pronouns', 'identify as', 'my gender'], 'identity', 18, 'permanent'),
          
        # Grief/Loss (Depth 15)
        (['died', 'passed away', 'funeral', 'loss of', 'grief', 'mourning'], 'grief', 15, 'established'),
        
        # Health (Depth 10-12)
        (['haven\'t slept', 'not sleeping', 'insomnia', 'can\'t sleep', 'sleeping well'], 'health', 12, 'recurring'),
        (['hospital', 'doctor', 'diagnosed', 'sick', 'illness'], 'health', 10, 'established'),
        
        # Emotional State (Depth 5-10)
        (['scared', 'terrified', 'panic', 'anxious', 'anxiety'], 'emotional_state', 10, 'immediate'),
        (['feel', 'feeling', 'i am sad', 'i\'m sad', 'depressed'], 'emotional_state', 5, 'today'),
        
        # Relationships (Depth 15)
        (['my mom', 'my dad', 'my partner', 'husband', 'wife', 'boyfriend', 'girlfriend'], 'relationships', 15, 'established'),
    ]
    
    detected_facts = []
    
    for sentence in sentences:
        clean_sentence = sentence.strip().lower()
        if len(clean_sentence) < 5:
            continue
            
        for keywords, domain, depth, temporal in rules:
            for kw in keywords:
                if kw in clean_sentence:
                    # Store the original sentence (capitalized nicely) as content
                    fact_content = sentence.strip()
                    
                    # Avoid duplicates in the same pass
                    if fact_content not in [f['content'] for f in detected_facts]:
                        detected_facts.append({
                            'domain': domain,
                            'depth': depth,
                            'temporal': temporal,
                            'content': fact_content
                        })
                    # Break inner keyword loop once rule matched
                    break
            # If we matched a rule for this sentence, move to next sentence
            # (Simple matching: one fact per sentence to avoid overcounting)
            if any(f['content'] == sentence.strip() for f in detected_facts):
                break

    # Store into lattice
    for fact in detected_facts:
        try:
            jane_lattice.store(
                username=username,
                domain=fact['domain'],
                depth=fact['depth'],
                temporal=fact['temporal'],
                content=fact['content']
            )
        except Exception as e:
            # Fail gracefully
            print(f"Error storing fact: {e}")
