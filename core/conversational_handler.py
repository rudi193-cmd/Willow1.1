# Generated by: Ollama Minimax (llm_router)
# Conversational handler for Kart - routes to local Ollama first, falls back to Free Fleet
import requests
from core import llm_router

def _ask_local_kart(user_message: str, context: list) -> str | None:
    """Call local Ollama kart model."""
    try:
        url = "http://localhost:11434/api/chat"
        payload = {
            "model": "kart",
            "messages": context,  # user_message already appended by agent_engine
            "stream": False
        }
        response = requests.post(url, json=payload, timeout=60)
        response.raise_for_status()
        data = response.json()
        return data.get("message", {}).get("content")
    except Exception:
        return None

def handle_conversational(user_message: str, context: list, tools_list=None) -> dict:
    # Build enhanced context with tools if provided
    enhanced_context = context.copy()
    if tools_list:
        tools_system_msg = {"role": "system", "content": "Available tools: " + ", ".join(tools_list)}
        enhanced_context.insert(0, tools_system_msg)

    # Try local Ollama first
    local_response = _ask_local_kart(user_message, enhanced_context)
    if local_response:
        context.append({"role": "assistant", "content": local_response})
        return {"response": local_response.strip(), "tool_calls": [], "provider": "ollama/kart", "tier": "local"}

    # Fallback to Free Fleet
    try:
        clean_system = "You are Kart: Direct, concise. 1-2 sentences. NO tool calls or JSON."
        if tools_list:
            clean_system += " Available tools: " + ", ".join(tools_list)
        prompt = clean_system + chr(10)*2 + "USER: " + user_message + chr(10) + "ASSISTANT:"
        response = llm_router.ask(prompt, preferred_tier="free")
        if response:
            context.append({"role": "assistant", "content": response.content})
            return {"response": response.content.strip(), "tool_calls": [], "provider": response.provider, "tier": response.tier}
        else:
            return {"response": "Connection error.", "tool_calls": [], "provider": "none", "tier": "free"}
    except Exception as e:
        return {"response": f"Error: {str(e)}", "tool_calls": [], "provider": "error", "tier": "free"}
