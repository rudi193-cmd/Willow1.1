# Generated by: Ollama GLM-5

import sqlite3
import os
from datetime import datetime
from typing import Optional, List, Dict, Any

# 
# CONSTANTS: 23-CUBED LATTICE DEFINITION
#

DOMAINS = [
    "emotional_state", "identity", "relationships", "health", "schedule", "preferences",
    "goals", "fears", "history", "location", "work", "crisis", "beliefs", "secrets", "children",
    "pets", "media", "finance", "education", "grief", "celebrations", "patterns", "meta"
]

TEMPORAL_STATES = [
    "immediate", "today", "this_week", "this_month", "recent", "established",
    "permanent", "archived", "seasonal", "recurring", "triggered", "dormant",
    "flagged", "sensitive", "verified", "inferred", "contested", "evolving",
    "forgotten", "recovered", "pending", "projected", "meta"
]

DEPTH_MIN = 1
DEPTH_MAX = 23
LATTICE_SIZE = len(DOMAINS) * DEPTH_MAX * len(TEMPORAL_STATES) # 12167

# Storage configuration
DB_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "jane_memory")

# 
# INTERNAL UTILITIES
#

def _ensure_db_dir():
    """Ensures the database directory exists."""
    if not os.path.exists(DB_DIR):
        os.makedirs(DB_DIR)

def _get_db_path(username: str) -> str:
    """Returns the specific database file path for a user."""
    return os.path.join(DB_DIR, f"{username}.db")

def _get_connection(username: str) -> sqlite3.Connection:
    """Establishes connection to the user's database."""
    _ensure_db_dir()
    db_path = _get_db_path(username)
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    return conn

def _init_schema(conn: sqlite3.Connection):
    """Initializes the lattice schema if it does not exist."""
    cursor = conn.cursor()
    # Enforce 23-cubed structure via unique constraint on lattice coordinates
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS nodes (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            username TEXT NOT NULL,
            domain TEXT NOT NULL,
            depth INTEGER NOT NULL,
            temporal TEXT NOT NULL,
            content TEXT NOT NULL,
            source TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            is_deleted INTEGER DEFAULT 0,
            is_sensitive INTEGER DEFAULT 0,
            UNIQUE(username, domain, depth, temporal)
        )
    """)
    
    # Indices for efficient recall queries
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain ON nodes (domain)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_temporal ON nodes (temporal)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_depth ON nodes (depth)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_sensitive ON nodes (is_sensitive)")
    
    conn.commit()

def _validate_coordinates(domain: str, depth: int, temporal: str):
    """Validates inputs against the 23-cubed lattice definition.
    Domains are open (any string accepted) to support multiple agents.
    Temporal and depth are still validated for lattice integrity.
    """
    if temporal not in TEMPORAL_STATES:
        raise ValueError(f"Invalid temporal state '{temporal}'. Must be one of: {TEMPORAL_STATES}")
    if not (DEPTH_MIN <= depth <= DEPTH_MAX):
        raise ValueError(f"Invalid depth '{depth}'. Must be between {DEPTH_MIN} and {DEPTH_MAX}")

# 
# PUBLIC API
#

def store(username: str, domain: str, depth: int, temporal: str, content: Any, source: Optional[str] = None) -> int:
    """
    Stores or updates a memory node at specific lattice coordinates.
    Returns the node ID.
    """
    _validate_coordinates(domain, depth, temporal)
    
    # Serialize content if it is not a string
    content_str = content if isinstance(content, str) else str(content)
    
    conn = _get_connection(username)
    try:
        _init_schema(conn)
        cursor = conn.cursor()
        
        now = datetime.now().isoformat()
        
        # Check if node exists at these coordinates to preserve created_at
        cursor.execute("""
            SELECT id, created_at FROM nodes 
            WHERE username=? AND domain=? AND depth=? AND temporal=?
        """, (username, domain, depth, temporal))
        row = cursor.fetchone()
        
        if row:
            # Update existing node (preserving original creation time)
            node_id = row['id']
            cursor.execute("""
                UPDATE nodes SET 
                    content = ?, 
                    source = ?, 
                    updated_at = ?, 
                    is_deleted = 0
                WHERE id = ?
            """, (content_str, source, now, node_id))
        else:
            # Insert new node
            cursor.execute("""
                INSERT INTO nodes (username, domain, depth, temporal, content, source, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (username, domain, depth, temporal, content_str, source, now, now))
            node_id = cursor.lastrowid
            
        conn.commit()
        return node_id
    finally:
        conn.close()

def recall(username: str, domain: Optional[str] = None, min_depth: int = 0, temporal: Optional[str] = None, limit: int = 20) -> List[Dict]:
    """
    Retrieves memory nodes matching criteria.
    Sorted by depth (descending) then recency.
    """
    conn = _get_connection(username)
    try:
        _init_schema(conn)
        cursor = conn.cursor()
        
        query = "SELECT * FROM nodes WHERE username = ? AND is_deleted = 0"
        params = [username]
        
        if domain:
            query += " AND domain = ?"
            params.append(domain)
            
        if min_depth > 0:
            query += " AND depth >= ?"
            params.append(min_depth)
            
        if temporal:
            query += " AND temporal = ?"
            params.append(temporal)
            
        query += " ORDER BY depth DESC, updated_at DESC LIMIT ?"
        params.append(limit)
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        return [dict(row) for row in rows]
    finally:
        conn.close()

def get_context_summary(username: str) -> Dict[str, Dict]:
    """
    Returns a dictionary of the most significant (deepest) node for each domain.
    """
    conn = _get_connection(username)
    try:
        _init_schema(conn)
        cursor = conn.cursor()
        
        # Fetch all non-deleted nodes, sorted by depth
        cursor.execute("""
            SELECT * FROM nodes 
            WHERE username = ? AND is_deleted = 0 
            ORDER BY domain, depth DESC
        """, (username,))
        
        rows = cursor.fetchall()
        summary = {}
        
        for row in rows:
            d = dict(row)
            domain = d['domain']
            # Only take the first encountered (deepest) node per domain
            if domain not in summary:
                summary[domain] = d
                
        return summary
    finally:
        conn.close()

def update_depth(username: str, node_id: int, new_depth: int):
    """
    Updates the significance depth of a specific node.
    Note: If this creates a coordinate collision, the DB constraint will block it.
    """
    if not (DEPTH_MIN <= new_depth <= DEPTH_MAX):
        raise ValueError(f"Depth must be between {DEPTH_MIN} and {DEPTH_MAX}")
        
    conn = _get_connection(username)
    try:
        cursor = conn.cursor()
        now = datetime.now().isoformat()
        cursor.execute("""
            UPDATE nodes SET depth = ?, updated_at = ?
            WHERE id = ? AND username = ?
        """, (new_depth, now, node_id, username))
        conn.commit()
    finally:
        conn.close()

def flag_sensitive(username: str, node_id: int):
    """Flags a node as sensitive."""
    conn = _get_connection(username)
    try:
        cursor = conn.cursor()
        now = datetime.now().isoformat()
        cursor.execute("""
            UPDATE nodes SET is_sensitive = 1, updated_at = ?
            WHERE id = ? AND username = ?
        """, (now, node_id, username))
        conn.commit()
    finally:
        conn.close()

def forget(username: str, node_id: int):
    """Soft deletes a node."""
    conn = _get_connection(username)
    try:
        cursor = conn.cursor()
        now = datetime.now().isoformat()
        cursor.execute("""
            UPDATE nodes SET is_deleted = 1, updated_at = ?
            WHERE id = ? AND username = ?
        """, (now, node_id, username))
        conn.commit()
    finally:
        conn.close()

def crisis_check(username: str) -> List[Dict]:
    """
    Checks for active crisis nodes.
    Returns nodes in 'crisis' domain that are not deleted and not in an inactive temporal state.
    """
    conn = _get_connection(username)
    try:
        _init_schema(conn)
        cursor = conn.cursor()
        
        # Define inactive temporal states
        inactive_states = ['archived', 'forgotten', 'dormant', 'resolved']
        
        query = """
            SELECT * FROM nodes 
            WHERE username = ? 
            AND domain = 'crisis' 
            AND is_deleted = 0 
            AND temporal NOT IN ({})
        """.format(','.join(['?'] * len(inactive_states)))
        
        params = [username] + inactive_states
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        return [dict(row) for row in rows]
    finally:
        conn.close()
