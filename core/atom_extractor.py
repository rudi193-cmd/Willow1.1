# Generated by: kart:latest (llm_router)
import sys, json, sqlite3, argparse, re
from pathlib import Path
from datetime import datetime, timezone

WILLOW_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(WILLOW_ROOT / "core"))
import llm_router
llm_router.load_keys_from_json()

DOMAINS = ["relationships","work","health","finance","creativity","learning","grief","family",
           "spirituality","identity","decisions","conflict","vision","gratitude","fear",
           "memory","body","nature","community","projects","travel","dreams","growth"]
DOMAIN_LIST = ", ".join(DOMAINS)

def get_db(username):
    db_path = WILLOW_ROOT / "artifacts" / username / "knowledge.db"
    conn = sqlite3.connect(str(db_path))
    _migrate(conn)
    return conn

def _migrate(conn):
    cur = conn.cursor()
    cur.execute("PRAGMA table_info(atoms)")
    atom_cols = {r[1] for r in cur.fetchall()}
    for col, defn in [("domain","TEXT"),("depth","INTEGER DEFAULT 1"),("source_session","TEXT")]:
        if col not in atom_cols:
            cur.execute(f"ALTER TABLE atoms ADD COLUMN {col} {defn}")
    cur.execute("PRAGMA table_info(entities)")
    ent_cols = {r[1] for r in cur.fetchall()}
    for col, defn in [("mention_count","INTEGER DEFAULT 1"),
                      ("first_seen","TIMESTAMP DEFAULT CURRENT_TIMESTAMP"),
                      ("last_seen","TIMESTAMP DEFAULT CURRENT_TIMESTAMP")]:
        if col not in ent_cols:
            cur.execute(f"ALTER TABLE entities ADD COLUMN {col} {defn}")
    cur.execute("PRAGMA table_info(gaps)")
    gap_cols = {r[1] for r in cur.fetchall()}
    for col, defn in [("context","TEXT"),("resolved","INTEGER DEFAULT 0")]:
        if col not in gap_cols:
            cur.execute(f"ALTER TABLE gaps ADD COLUMN {col} {defn}")
    cur.execute("""CREATE TABLE IF NOT EXISTS patterns (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        description TEXT NOT NULL, domain TEXT,
        frequency INTEGER DEFAULT 1,
        first_detected TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        last_detected TIMESTAMP DEFAULT CURRENT_TIMESTAMP)""")
    conn.commit()

def read_session(session_file):
    events = []
    with open(session_file, encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                events.append(json.loads(line))
    session_id = consent_state = None
    texts = []
    for ev in events:
        t = ev.get("type", "")
        p = ev.get("payload", {})
        if t == "session.start":
            session_id = p.get("session_id")
            consent_state = p.get("consent_state", "write")
        elif t == "note":
            texts.append(p.get("text", "").strip())
        elif t == "context.add" and p.get("ref"):
            texts.append("[context: " + p["ref"] + "]")
        elif t == "decision.log" and p.get("decision"):
            texts.append("[decision: " + p["decision"] + "]")
    return {"session_id": session_id, "consent_state": consent_state,
            "text": "\n\n".join(t for t in texts if t)}

def extract_atoms_llm(text):
    prompt = (
        "Atom extractor for a journal pipeline. Return ONLY valid JSON.\n"
        "DOMAINS: " + DOMAIN_LIST + "\n\n"
        "Extract atoms(content/domain/depth 1-3), entities(name/type:person|place|org|concept), "
        "gaps(question/context), patterns(description/domain).\n"
        'Shape: {"atoms":[],"entities":[],"gaps":[],"patterns":[]}\n'
        "Empty sections=[]. Do not invent.\n\nSESSION:\n---\n" + text + "\n---"
    )
    response = llm_router.ask(prompt, preferred_tier="free")
    if not response:
        return {"atoms": [], "entities": [], "gaps": [], "patterns": []}
    content = response.content.strip()
    if content.startswith("```"):
        lines = content.split("\n")
        end = next((i for i in range(len(lines)-1,0,-1) if lines[i].strip()=="```"), len(lines))
        content = "\n".join(lines[1:end])
    try:
        return json.loads(content)
    except Exception:
        m = re.search(r"\{.*\}", content, re.DOTALL)
        if m:
            try: return json.loads(m.group())
            except Exception: pass
        print(f"[atom_extractor] parse failed:\n{content[:300]}", file=sys.stderr)
        return {"atoms": [], "entities": [], "gaps": [], "patterns": []}

def store_results(conn, session_id, extracted):
    cur = conn.cursor()
    now = datetime.now(timezone.utc).isoformat()
    counts = {"atoms": 0, "entities": 0, "gaps": 0, "patterns": 0}
    for a in extracted.get("atoms", []):
        c = a.get("content", "").strip()
        if c:
            cur.execute("INSERT INTO atoms (content,source_session,domain,depth,created) VALUES(?,?,?,?,?)",
                        (c, session_id, a.get("domain"), a.get("depth", 1), now))
            counts["atoms"] += 1
    for e in extracted.get("entities", []):
        name = e.get("name", "").strip()
        if not name: continue
        cur.execute("SELECT id,mention_count FROM entities WHERE name=?", (name,))
        row = cur.fetchone()
        if row:
            cur.execute("UPDATE entities SET mention_count=?,last_seen=? WHERE id=?", (row[1]+1, now, row[0]))
        else:
            cur.execute("INSERT INTO entities (name,type,mention_count,first_seen,last_seen) VALUES(?,?,?,?,?)",
                        (name, e.get("type","concept"), 1, now, now))
        counts["entities"] += 1
    for g in extracted.get("gaps", []):
        q = g.get("question", "").strip()
        if q:
            cur.execute("INSERT INTO gaps (question,context,created,resolved) VALUES(?,?,?,0)",
                        (q, g.get("context",""), now))
            counts["gaps"] += 1
    for p in extracted.get("patterns", []):
        d = p.get("description", "").strip()
        if not d: continue
        cur.execute("SELECT id,frequency FROM patterns WHERE description=?", (d,))
        row = cur.fetchone()
        if row:
            cur.execute("UPDATE patterns SET frequency=?,last_detected=? WHERE id=?", (row[1]+1, now, row[0]))
        else:
            cur.execute("INSERT INTO patterns (description,domain,frequency,first_detected,last_detected) VALUES(?,?,?,?,?)",
                        (d, p.get("domain"), 1, now, now))
        counts["patterns"] += 1
    conn.commit()
    return counts

def get_latest_session(username):
    d = WILLOW_ROOT / "artifacts" / username / "journal"
    if not d.exists(): return None
    files = sorted(d.glob("*.jsonl"), key=lambda p: p.stat().st_mtime, reverse=True)
    return files[0] if files else None

def check_threshold(conn):
    cur = conn.cursor()
    cur.execute("SELECT domain,COUNT(*) FROM atoms WHERE domain IS NOT NULL GROUP BY domain ORDER BY 2 DESC")
    rows = cur.fetchall()
    alerts = []
    for dom, cnt in rows:
        if cnt >= 216: alerts.append(f"{dom}: {cnt} - READY (Book Part 1)")
        elif cnt >= 180: alerts.append(f"{dom}: {cnt} - approaching ({216-cnt} to Part 1)")
    return rows, alerts

def run(username, session_file):
    s = read_session(session_file)
    cs = s["consent_state"]
    if cs not in ("learn", "remember", "become"):
        print(f"Consent {cs!r} requires learn+. Skipping."); return
    txt = s["text"]
    if not txt.strip():
        print("No text."); return
    sid = s["session_id"]
    print(f"Extracting {sid} ({len(txt)} chars)...")
    extracted = extract_atoms_llm(txt)
    conn = get_db(username)
    counts = store_results(conn, sid, extracted)
    ac, ec, gc, pc = counts["atoms"], counts["entities"], counts["gaps"], counts["patterns"]
    print(f"Stored: {ac} atoms | {ec} entities | {gc} gaps | {pc} patterns")
    _, alerts = check_threshold(conn)
    for a in alerts: print(f"[Books of Life] {a}")
    conn.close()

def main():
    parser = argparse.ArgumentParser(description="Extract atoms from journal sessions")
    parser.add_argument("username")
    parser.add_argument("session", nargs="?")
    parser.add_argument("--latest", action="store_true")
    parser.add_argument("--stats", action="store_true")
    args = parser.parse_args()
    if args.stats:
        conn = get_db(args.username)
        rows, alerts = check_threshold(conn)
        print(f"Total atoms: {sum(c for _,c in rows)}")
        for dom, cnt in rows:
            bar = "#" * (cnt // 5)
            print(f"  {dom:<15} {cnt:>4}  {bar}")
        for a in alerts: print(f"[!] {a}")
        conn.close(); return
    if args.latest:
        sf = get_latest_session(args.username)
        if not sf: print(f"No sessions for {args.username}"); sys.exit(1)
        print(f"Using: {sf.name}")
    elif args.session:
        sf = Path(args.session)
    else:
        parser.print_help(); sys.exit(1)
    run(args.username, sf)

if __name__ == "__main__":
    main()
